Thinking...
Okay, I need to write an R program using data.table to accomplish this task. Let me break it down step by step.

First, I need to read two CSV files into data.tables:
1. 'offices.csv' should be read into a data.table called 'offices'. It has two columns: 'employee_id' and 'work_address'.
2. 'homes.csv' should be read into a data.table called 'homes'. It also has two columns: 'employee_id' and 'home_address'.

Next, I need to join these two data.tables on the 'employee_id' column. The result should have three columns: 'employee_id', 'work_address', and 'home_address'. Importantly, only rows where the 'employee_id' exists in both tables should be included.

Finally, I need to write this joined table to a file called 'result.csv'.

Now, let's think about how to implement this using data.table in R. The main functions I'll need are:
1. `fread()` for reading CSV files (since it's from the data.table package)
2. `merge()` or `join()` operation to combine the tables
3. `fwrite()` to write the result to a CSV file

First, I need to ensure that both input files exist and can be read. The task assumes they do, so I'll proceed with reading them into data.tables.

For joining, since we want only rows where employee_id exists in both tables, it's an inner join. In data.table terms, this would be a `merge` with `all.x=FALSE, all.y=FALSE`.

But looking at the documentation, data.table has a `merge` function that works like SQL joins. The default is similar to SQL's inner join when both `all.x` and `all.y` are FALSE.

Alternatively, I could use the new join syntax introduced in data.table 1.9.5 (I think), which uses `on=column_name` for joining.

Let me think about the exact syntax:

```r
library(data.table)
# Read the files
offices <- fread('offices.csv')
homes <- fread('homes.csv')

# Join them on employee_id
result <- merge(offices, homes, by = "employee_id", all = FALSE)

# Alternatively:
# result <- offices[homes, on = "employee_id"]
```

But the first approach with `merge` seems more readable. The `all=FALSE` ensures it's an inner join.

After joining, I need to select only the columns 'employee_id', 'work_address', and 'home_address'. But looking at the merge result:
- The joined table will have employee_id (the key), work_address from offices, and home_address from homes.
But in data.table's merge, by default it keeps all columns except the join key is duplicated. Wait no - actually with `by`, it keeps all columns but adds a suffix to avoid name clashes.

Wait, let me check:
When using `merge(offices, homes, by = "employee_id")`:
- The resulting table will have columns: employee_id (the join key), then work_address from offices and home_address from homes.
But if there are other columns with the same names in both tables, they'll get suffixes like .x and .y. But in our case, we only have two columns each with distinct names ('work_address' vs 'home_address'), plus the join column.

Wait no - looking at the structure:
offices has: employee_id, work_address
homes has: employee_id, home_address

When merging on employee_id, the result will have:
employee_id (from either table), work_address (from offices), and home_address (from homes).

So we don't need to do any column selection - it's already correct.

But what if the input files have other columns? The problem states they only have these two columns each, so we're good.

Now, write this result to 'result.csv'. For data.tables, `fwrite()` is more efficient than write.csv().

So putting it all together:

```r
library(data.table)

# Read the input files
offices <- fread('offices.csv')
homes <- fread('homes.csv')

# Join them on employee_id with inner join (all.FALSE)
result <- merge(offices, homes, by = "employee_id", all = FALSE)

# Write to result.csv
fwrite(result, 'result.csv')
```

But wait - the problem says the output table should have columns in this order: employee_id, work_address, home_address. Does `merge` preserve the column order? I'm not sure.

Looking at data.table's merge documentation, it puts the join key first, followed by columns from the left table (with suffixes if needed), then columns from the right table (with suffixes if needed).

In our case:
- offices: employee_id, work_address
- homes: employee_id, home_address

After merging on employee_id with by="employee_id":
The result will have:
1. employee_id (the join key)
2. work_address (from offices)
3. home_address (from homes)

Which is exactly the order we want! So no need for column reordering.

But just to be safe, maybe I should specify the columns explicitly when writing:

```r
fwrite(result[, c("employee_id", "work_address", "home_address")], 'result.csv')
```

But in our case since merge gives us exactly what we want, this isn't necessary. But it's good practice if we're unsure about column ordering.

Let me verify the column order with a quick test:

```r
# Sample data
offices <- data.table(employee_id = c("1", "2"), work_address = c("A", "B"))
homes <- data.table(employee_id = c("1", "3"), home_address = c("X", "Y"))

result <- merge(offices, homes, by = "employee_id")
print(result)
```

This would give:
employee_id work_address home_address
1:          1             A              X

Which has the correct column order. So our initial approach is correct.

But what if there are duplicate employee_ids? The problem doesn't specify, but typically we'd want to keep all duplicates that match in both tables. An inner join (which merge with all.FALSE does) will keep all combinations where the key exists in both tables. For example, if employee_id 1 appears twice in offices and once in homes, there would be two rows for employee_id 1 in the result.

But since the problem doesn't specify handling of duplicates, we'll proceed with this standard join behavior.

One more thing to consider: what data types are these columns? The problem says they're text columns. In R/data.table terms, that means character type (not factor). fread() should read them as character by default unless there's some inference happening.

But since the problem specifies they're text columns, we might want to ensure they stay as character vectors rather than being converted to factors (which was common in older versions of R).

In modern R/data.table, fread() will typically read strings as character type unless they have factor levels defined somewhere. But to be safe, maybe we should convert them explicitly.

But the problem doesn't specify that we need to ensure the types remain text - just that they are text columns in the input and output. Since CSV files don't preserve R's type system (they're all text when read), and fwrite() writes them as-is, we should be fine without explicit type conversion unless there's a specific issue.

Therefore, our initial solution seems correct and complete.
...done thinking.

### Solution

Here is the R program using data.table that accomplishes the specified task:

```r
library(data.table)

# Read the input files into data.tables
offices <- fread('offices.csv')
homes <- fread('homes.csv')

# Perform an inner join on employee_id
result <- merge(offices, homes, by = "employee_id", all = FALSE)

# Write the result to a CSV file
fwrite(result, 'result.csv')
```

### Explanation

1. We load the `data.table` package which provides efficient data table operations.
2. We read both input files ('offices.csv' and 'homes.csv') into data.tables using `fread()`, which is optimized for speed with CSV files.
3. We perform an inner join on the 'employee_id' column between 'offices' and 'homes' using `merge()` with `all=FALSE` to ensure only matching rows are included.
4. Finally, we write the joined result to 'result.csv' using `fwrite()`, which is more efficient than R's base `write.csv()`.

This solution assumes that both input files exist in the working directory and have the correct structure (two text columns with matching names). The output will contain only rows where employee_id appears in both tables, as requested.

\boxed{result.csv}

