Thinking...
Okay, I need to write an R program using data.table to accomplish four main tasks:
1. Read two CSV files into data.table objects.
2. Join these tables based on a common column ('employee_id').
3. Filter the result to include only rows where 'employee_id' exists in both input tables.
4. Write the final joined table to a new CSV file.

First, I need to make sure I have the necessary libraries installed and loaded. The problem specifies using data.table, so I'll need to ensure that library is available.

For step 1, reading files into data.table objects:
- I recall that data.table has a function `fread` for reading CSV files.
- So, I'll use `fread('offices.csv')` to read the first file into 'offices'.
- Similarly, `fread('homes.csv')` will read the second file into 'homes'.

For step 2 and 3, joining and filtering:
- The problem asks for an inner join on 'employee_id' since we only want rows where the id exists in both tables.
- In data.table, this is done with the `data.table` package's merge functionality or using `inner_join` from dplyr, but since it's specified to use data.table, I should stick to that.
- So, I'll join 'offices' and 'homes' on 'employee_id'. But before joining, I need to ensure both tables have this column. The problem states they do, so I'm good.
- The joined table should only contain rows where 'employee_id' exists in both tables, which is exactly what an inner join does.

For step 4, writing the result:
- After joining, I'll use `fwrite` from data.table to write the result to 'result.csv'.
- The problem specifies the output columns should be 'employee_id', 'work_address', and 'home_address'. So after joining, I might need to select only these columns or rename columns if necessary.

But looking at the input tables:
- 'offices' has 'employee_id' and 'work_address'.
- 'homes' has 'employee_id' and 'home_address'.

After joining on 'employee_id', the result will have all four columns, but we need to select only three: 'employee_id', 'work_address', and 'home_address'. Since both input tables have 'employee_id', after joining, there might be two 'employee_id' columns (one from each table). But since it's a join on that column, data.table will likely merge them into one. I need to confirm this.

Actually, in R, when you join tables with common column names, the result will have the non-key columns from both tables, and the key column will appear once. So after joining 'offices' and 'homes' on 'employee_id', the resulting table should have columns: 'employee_id', 'work_address', 'home_address'. That matches exactly what we need for the output.

But to be safe, I might want to explicitly specify the columns in the output:
- Select only the three required columns after joining.
Alternatively, since the join will naturally produce these columns (assuming no other columns are present), perhaps no further selection is needed. But looking back at the problem statement: "The output table should have text columns 'employee_id', 'work_address' and 'home_address'". So even if the join produces exactly these columns, it's good practice to explicitly select them in case there are others or for clarity.

But according to the problem, the input tables only have these two columns each (with different second column names). So after joining on 'employee_id', the result will have:
- employee_id (from either table, since they're joined)
- work_address (from offices)
- home_address (from homes)

So no need for additional selection, unless there are duplicate column names which isn't the case here.

Therefore, the steps in R would be:
1. Load data.table library.
2. Read 'offices.csv' into 'offices'.
3. Read 'homes.csv' into 'homes'.
4. Perform an inner join on 'employee_id' between offices and homes.
5. Write the result to 'result.csv'.

But wait, does data.table's merge/join by default do an inner join? Or is there a specific function for that?

Looking at data.table documentation:
- The `data.table` package uses `[` or `merge.data.table` for joins.
- By default, `offices[homes, on="employee_id"]` would perform a left join (all rows from offices matching with homes).
But we need an inner join, which is all rows that match in both tables. For that, we can use `inner_join` from dplyr, but since the problem specifies using data.table, I need to do it with data.table functions.

In data.table, for inner joins specifically, you can:
- Use `merge(offices, homes, by="employee_id")` with `all.x=FALSE, all.y=FALSE` for an inner join.
But actually, the default merge in R/data.table is a subset of the SQL left join. For inner join, we need to specify that we only want rows where keys match in both tables.

Actually, looking at `?data.table`, the `[` operator can be used for various types of joins based on whether you're indexing with data.table or not.

The syntax `x[i]` is a subset, but when `i` is another data.table, it's a join.
By default, `offices[homes]` would do a left join (all rows from offices where key matches in homes).
For inner join, we need to use `homes[offices]` if we want all rows from homes that match in offices, but neither is exactly what we want.

Wait, no. The correct way for an inner join is:
`result <- offices[homes, on="employee_id", nomatch=0]`
But I think by default, `on=` does a left join where the x (offices) is the left table and y (homes) is the right table.

Actually, looking at data.table's documentation, to get an inner join, we can use:
`merge(offices, homes, by="employee_id")` with default parameters (all.x=FALSE, all.y=FALSE), which gives the intersection of both tables based on the key.

But let me check:
In SQL terms:
- INNER JOIN would only return rows where keys match in both tables.
- LEFT JOIN would return all rows from left table plus matches from right table.
- RIGHT JOIN is opposite.
- FULL OUTER JOIN would return all rows when there's a match in either table.

`merge(offices, homes, by="employee_id")` with default parameters does a full outer join? No, actually the default is all.x=TRUE and all.y=TRUE which would be a full outer join. Wait no:

From `?merge.data.table`:

The default is all.x = TRUE and all.y = FALSE, which is a left join (all rows of x and matching rows from y).

So to get an inner join, we need both all.x=FALSE and all.y=FALSE.

Therefore, the correct way would be:
`result <- merge(offices, homes, by="employee_id", all=FALSE)`

This will give us only rows where 'employee_id' exists in both tables, which is what we want.

Then, since the problem specifies that the output should have columns 'employee_id', 'work_address', and 'home_address', and our merge will produce exactly these columns (since offices has employee_id and work_address, homes has employee_id and home_address, and we're joining on employee_id), so no further column selection is needed.

But to be precise, let's see what columns the merged table would have:
- The key column 'employee_id' from both tables will be combined into one.
- Then all other columns: 'work_address' from offices and 'home_address' from homes.

So the result will have exactly these three columns in some order. But the problem specifies the output should have them in this specific order.

But data.table's merge doesn't guarantee column order, so perhaps we should explicitly set the column order after merging.

Alternatively, since the column names match what we want (except for employee_id which is fine), and assuming no other columns are present, we might not need to do anything else. But to be safe, we can select and order the columns as specified.

So steps would be:
1. Load library(data.table)
2. offices <- fread('offices.csv')
3. homes <- fread('homes.csv')
4. result <- merge(offices, homes, by="employee_id", all=FALSE)
5. result <- result[, .(employee_id, work_address, home_address)] # to order columns as specified
6. fwrite(result, 'result.csv')

But wait, does `merge` with `all=FALSE` really do an inner join? Let me think:
- all.x=FALSE means we don't keep rows from x (offices) that don't have matches in y (homes).
- all.y=FALSE means we don't keep rows from y (homes) that don't have matches in x (offices).
So only rows where keys match in both are kept, which is indeed an inner join.

Therefore, the above steps should work.

But to confirm column order: if we do as.db.data.table or similar it might not be necessary since CSV doesn't care about order unless specified. The problem says "should have text columns 'employee_id', 'work_address' and 'home_address'", which I interpret as these are the required columns, but order isn't strictly specified (though it's good practice to match the given order).

So perhaps step 5 is unnecessary unless we want to enforce column order.

But looking at the problem statement: "The output table should have text columns 'employee_id', 'work_address' and 'home_address'", which specifies both the names and the order. So to be precise, we should ensure that's the exact column order in the output.

So step 5 is necessary to set the column order as specified.

Final code would be:

```r
library(data.table)
offices <- fread('offices.csv')
homes <- fread('homes.csv')
result <- merge(offices, homes, by="employee_id", all=FALSE)
result <- result[, .(employee_id, work_address, home_address)]  # reorder columns as specified
fwrite(result, 'result.csv')
```

But wait, does `merge` with `by` automatically handle the column names correctly? Let me think:
When we merge on "employee_id", and since both tables have this column, the merged result will have one employee_id column (from either table) and then the other columns from each. So in our case, offices contributes 'work_address' and homes contributes 'home_address', so the resulting data.table should have all three columns we need.

But to ensure that, perhaps it's better to explicitly list which columns to keep from each table during merge. The `merge` function has an `all.x` and `all.y` parameter for inner join (both FALSE), but also allows specifying which columns to take from x and y.

Looking at help:
merge(x, y, by, all.x=TRUE, all.y=TRUE)

But we can also do:
result <- offices[homes, on="employee_id", nomatch=0]

Wait, no. Actually in data.table, the `[` operator is more flexible for joins.

From `?data.table`:

For join operations, when the first argument is a data.table and the second is another data.table, it performs a left join by default (with some variations based on parameters).

To perform an inner join using `[`, you can use:
result <- offices[homes, on="employee_id", nomatch=0]

Here's why:
- `x[i]` where i is another data.table does a left join by default.
- But if we do `i[x]`, it would be different (right join).
But we want to keep only rows where the key exists in both tables, which is inner join.

Actually, with `nomatch=0`:
"When joining data.tables, if the type of the join column is integer or logical and NA (getNA()) is not present in x but is present in i, then by default (with nomatch=0) rows from x where the key doesn't match in i are removed."

But for our case, since we're doing `offices[homes, ...]`, this would be a left join where we keep all rows from homes that match in offices. Wait no:

Wait, let's clarify:

In data.table, `x[y, on=...]` does:
- For each row in y (right table), find matching rows in x (left table).
So if we do `offices[homes, ...]`, it's like a left join where for each row in homes, we look for matching rows in offices.

But for inner join, we want all rows where the key exists in both. So this would not work directly because:
- If a row is in homes but not in offices, `offices[homes,...]` with default parameters would keep that row from homes and fill with NA's from offices.
But with `nomatch=0`, such rows are removed.

So `offices[homes, on="employee_id", nomatch=0]` would:
1. Start with all rows in homes (the right table).
2. For each row in homes, find matching rows in offices based on employee_id.
3. If no match is found, the row is dropped because of `nomatch=0`.
4. Otherwise, the matched rows are combined.

This is actually a semi-join: it returns all rows from homes that have matches in offices, plus columns from both tables where they match. But since we're selecting columns after, this would work for our case because:
- It ensures that employee_id exists in both tables (since unmatched rows from homes are dropped).
- Then for the remaining rows, it combines data from both tables.

But wait, what if there's a row in offices not present in homes? That wouldn't be included in the result at all, which is correct because we want only rows where employee_id exists in both.

So this approach seems to give us an inner join-like result (but actually it's more like a semi-join followed by left join with the remaining data).

But perhaps the simplest way is indeed to use `merge` with `all=FALSE`.

Alternatively, another way to do inner join in data.table is:

```r
result <- offices[homes, on="employee_id", nomatch=0][,
    .(employee_id = employee_id, work_address, home_address),
    by = employee_id]
```

But this seems convoluted. Maybe stick with merge.

Final approach using `merge`:

1. Read data.
2. Merge with all=FALSE for inner join on employee_id.
3. Reorder columns as required.
4. Write to file.

So the code would be:

```r
library(data.table)
offices <- fread('offices.csv')
homes <- fread('homes.csv')
result <- merge(offices, homes, by="employee_id", all=FALSE)
# Ensure column order as specified in problem statement
result <- result[, c("employee_id", "work_address", "home_address")]
fwrite(result, 'result.csv')
```

But wait, does `merge` with `by="employee_id"` keep the employee_id column from both tables? Or does it merge them?

Actually, when you merge on a common column name (employee_id in both tables), data.table will combine them into one column in the result. So the resulting table should have:
- employee_id (combined)
- work_address (from offices)
- home_address (from homes)

So no need to handle duplicate employee_id columns.

Thus, after merge with all=FALSE, we just need to ensure the column order is correct, which can be done by selecting columns in the desired order as shown above.

Therefore, final code:

```r
library(data.table)
offices <- fread('offices.csv')
homes <- fread('homes.csv')
result <- merge(offices, homes, by="employee_id", all=FALSE)
# Select and order columns as required
result <- result[, .(employee_id, work_address, home_address)]
fwrite(result, 'result.csv')
```

This should satisfy all requirements:
1. Reads both files into data.tables.
2. Performs an inner join on employee_id (all.FALSE in merge).
3. Selects only the required columns in the specified order.
4. Writes to result.csv.

One potential issue: what if there are duplicate employee_ids in either table? The problem doesn't specify, but typically employee_id would be unique per table. If not, the join would produce multiple rows for a single employee_id (one for each matching pair between offices and homes).

But since the problem mentions "only have a row if the 'employee_id' exists in both input tables", it implies that within each table, employee_ids are unique (or at least we're treating them as keys). If there are duplicates within one table, the join would multiply those rows.

If we assume employee_id is unique within each table, then the above solution works. Otherwise, if an employee_id appears multiple times in either table, the result will have all combinations of matching rows between offices and homes for that id.

But since the problem doesn't specify handling duplicates, we'll proceed with the basic join operation.
...done thinking.

### Solution

The following R program uses `data.table` to accomplish the specified task:

```r
library(data.table)

# Read the input files into data.tables
offices <- fread('offices.csv')
homes <- fread('homes.csv')

# Perform an inner join on 'employee_id' and select only the required columns
result <- merge(offices, homes, by="employee_id", all=FALSE)[,
    .(employee_id, work_address, home_address)]

# Write the result to a CSV file
fwrite(result, 'result.csv')
```

### Explanation:
1. The `data.table` package is loaded for efficient data manipulation.
2. The input files are read into `data.table` objects using `fread`.
3. An inner join is performed on the 'employee_id' column by setting `all=FALSE` in the `merge` function, which ensures only matching rows from both tables are retained.
4. The resulting table is ordered to have columns 'employee_id', 'work_address', and 'home_address'.
5. Finally, the result is written to 'result.csv' using `fwrite`.

This solution efficiently handles the data manipulation tasks while adhering to the specified requirements.

\boxed{result}

