Thinking...
Alright, let's see. I need to write an R program using data.table to do some specific tasks. Hmm, so first, I should probably start by understanding what each step requires.

Okay, step 1 is to read a file called 'offices.csv' into a data.table named 'offices'. The columns are 'employee_id' and 'work_address', both text. So in R, I'll use the fread function from data.table because it's efficient for reading CSV files.

Similarly, step 2 involves reading another CSV file, 'homes.csv', into a data.table called 'homes'. It also has two columns: 'employee_id' and 'home_address'. Again, using fread should work here.

Now, step 3 is where I need to perform a join. The goal is to create a joined data.table called 'result' that includes only the rows where 'employee_id' exists in both 'offices' and 'homes'. So this sounds like an inner join on 'employee_id'.

I remember that in data.table, joining can be done using the merge function or by setting keys. Maybe I should set the key to 'employee_id' for both tables before merging. That way, the merge operation will efficiently combine them based on that key.

After the merge, the resulting table should have columns: employee_id, work_address, and home_address. So I need to make sure that during the join, these three columns are included without duplication.

Finally, step 4 is writing this result to a CSV file named 'result.csv'. In R, using fwrite from data.table is efficient for writing large datasets, which might be better than write.csv for performance, especially if the tables are big.

Wait, but what about handling cases where employee_id isn't present in both tables? Since it's an inner join, those employees who aren't in both will be excluded. That makes sense as per the requirements.

Also, I should ensure that all necessary libraries are loaded at the beginning. So, requiring data.table would be essential before using any of its functions.

Putting this together, my plan is:

1. Load the data.table package.
2. Read 'offices.csv' into offices data.table.
3. Read 'homes.csv' into homes data.table.
4. Set the key for both tables to 'employee_id'.
5. Merge the two tables on employee_id using an inner join.
6. Write the resulting merged table to 'result.csv'.

I should test each step as I go, maybe print out the structure of each data.table after reading them to ensure they're correct. Also, checking that the number of rows in the result makes sense based on the input files.

Wait a second, do I need to handle any potential duplicates? Like if an employee_id appears multiple times in either file. The problem doesn't specify handling such cases, so perhaps it's safe to assume each employee_id is unique per table. If not, the inner join would just pair all combinations of matching employee_ids, but that might complicate things. Since the problem states "only have a row if the employee_id exists in both," maybe it implies one-to-one matches.

Alternatively, if there are multiple entries for an employee in either file, the merge will produce all combinations, which could lead to more rows than intended. But since the instruction doesn't specify handling that scenario, perhaps we can proceed under the assumption that each employee_id is unique in both tables.

So, moving forward with setting keys and merging should suffice.
...done thinking.

To accomplish the tasks outlined using `data.table` in R, follow these steps:

### Solution Code

```r
# Load required library
library(data.table)

# Read offices.csv into a data.table named 'offices'
offices <- fread("offices.csv")

# Read homes.csv into a data.table named 'homes'
homes <- fread("homes.csv")

# Set the key for joining on employee_id in both tables
setkey(offices, employee_id)
setkey(homes, employee_id)

# Perform an inner join to get only matching employee_ids
result <- offices[homes]

# Write the joined result to result.csv without row names
fwrite(result, "result.csv", sep = ",", quote = FALSE)
```

### Explanation

1. **Reading Data**: The `fread` function efficiently reads the CSV files into data.tables named `offices` and `homes`.

2. **Setting Keys**: By setting `employee_id` as the key in both tables using `setkey`, we enable efficient joining operations.

3. **Joining Tables**: Using `[ ]` with `offices[homes]` performs an inner join, resulting in a table containing only rows where `employee_id` exists in both files. This operation is optimized for performance due to the keys set earlier.

4. **Writing Output**: The `fwrite` function writes the joined data.table to a CSV file named `result.csv`, ensuring efficient writing with specified separators and no quotes around fields.

This approach efficiently handles the joining of large datasets using `data.table`'s optimized functions, providing an effective solution for merging employee data from two sources.

